---
content_type: resource
description: ''
file: null
resourcetype: Video
title: 'Lecture 26: Structure of Neural Nets for Deep Learning'
uid: 2cf9f8cb-f7d4-0639-7a5c-f4361ec9fc66
video_files:
  archive_url: https://ia801404.us.archive.org/25/items/MIT18.065S18/MIT18_065S18_Lecture26_300k.mp4
  video_captions_file: /courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/d776d03c1a5f55909ea338862b63bec8_sx00s7nYmRM.vtt
  video_thumbnail_file: https://img.youtube.com/vi/sx00s7nYmRM/default.jpg
  video_transcript_file: /courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/a9535204dab31ed87499c11cd579c49d_sx00s7nYmRM.pdf
video_metadata:
  youtube_id: sx00s7nYmRM
---

**Description**
---------------

This lecture is about the central structure of deep neural networks, which are a major force in machine learning. The aim is to find the function thatâ€™s constructed to learn the training data and then apply it to the test data.

**Summary**
-----------

The net has layers of nodes. Layer zero is the data.  
We choose matrix of "weights" from layer to layer.  
Nonlinear step at each layer! Negative values become zero!  
We know correct class for the training data.  
Weights optimized to (usually) output that correct class.

Related section in textbook: VII.1

**Instructor:** Prof. Gilbert Strang